---
title: "Predicting Song Popularity - Model Testing"
subtitle: "STAT 420, Summer 2023, UIUC - Final Data Project"
author: "Soumya Nanda, Jonas Jansen, Noam Isachar"
output:
  pdf_document: default
  theme: readable
  toc: yes
  html_document:
urlcolor: cyan
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")
```

------------------------------------------------------------------------

Extracted this file for faster computations on model finding.
The final models should be included into the report file.

```{r, warning = FALSE}
library(knitr)
library(ggplot2)
library(GGally)
library(MASS)
library(gridExtra)
library(lmtest)
library(car)
```



# Load prepared train dataset (currently 10% of all entries). Convert necessary variables into factors.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
data_raw <- read.csv("../data/spotify_data_trn.csv")
data_trans_raw  <- read.csv("../data/spotify_data_transformed_trn.csv")
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
data_raw$upper_genre <- factor(data_raw$upper_genre)
data_raw$key <- factor(data_raw$key)
data_raw$mode <- factor(data_raw$mode)
data_raw$time_signature <- factor(data_raw$time_signature)
str(data_raw)

data_trans_raw$year <- data_raw$year
data_trans_raw$genre <- factor(data_raw$genre)
data_trans_raw$upper_genre <- factor(data_raw$upper_genre)
data_trans_raw$key <- factor(data_raw$key)
data_trans_raw$mode <- factor(data_raw$mode)
data_trans_raw$time_signature <- factor(data_raw$time_signature)
str(data_trans_raw)
```


# Model finding

### Prepare test and Train data.

For an easier model fitting, let's create a data set without `artist_name` and `track_name`.

TODO: Split into test and train



### Model Test Stats

Create a function, that is performing several test on the model and return the results.

```{r}
check_model = function(model, test_data){
  sample_idx = sample(length(resid(model)), 5000)
  residuals_sample = resid(model)[sample_idx]
  
  # shapiro
  shapiro =  shapiro.test(residuals_sample)$p.value
  
  # bp test
  bptest = bptest(model)$p.value
  
  # leverage
  high_leverage_count = sum(hatvalues(model) > 2 * mean(hatvalues(model)))
  
  # outliers
  outliers_count = length(rstandard(model)[abs(rstandard(model)) > 2])
  
  # influence
  influence_count = sum(cooks.distance(model) > 4 / length(cooks.distance(model)))
  
  
  # loocv_rmse
  loocv_rmse = sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
  
  # adjusted r squared
  adjusted_r_squared = summary(model)$adj.r.squared

  # TODO: Some test to test against the test_data
  
  # Creating a data frame to store the results
  results = data.frame(
    shapiro = shapiro,
    bptest = bptest,
    high_leverage_count = high_leverage_count,
    outliers_count = outliers_count,
    influence_count = influence_count,
    loocv_rmse = loocv_rmse,
    adjusted_r_squared = adjusted_r_squared
  )

  results

}
```


### 1. Full additive.

First try, fit an full additive model with popularity as response.

```{r, warning=FALSE}
data = subset(data_raw, select = -c(upper_genre))
```


```{r}
model_add_full = lm(popularity ~ ., data = data)
```

Let's do some first tests.

```{r}
summary(model_add_full)
```
What we can see is:
- p-value is very low 
- most variables are siginficant. Except some categorical keys.
- RSS?
- Adjusted R => Okay, but could be better.

Model seems decent, but we can do better.

Trying to find a smaller good model. Using both AIC or BIC running backward did not lead to smaller models. 


Let's have a look into the test results:

```{r}
results = check_model(model_add_full, data_tst)
results
```

The test results make show that the normality and constant variance and normal assumption.
The Plots Fitted vs Residuals underline that.


```{r}
plot(fitted(model_add_full), resid(model_add_full), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residual",
     main = "Full Additive Model - Fitted vs Residuals")
abline(h = 0, col = "darkorange", lwd = 2)
```

```{r}
qqnorm(resid(model_add_full), col = "darkgrey")
qqline(resid(model_add_full), col = "dodgerblue", lwd = 2)
```

The model needs adjustments. Transformations could be helpful to fullfill the assumptions.



### 2. Smaller addtive models, but more explainable

In terms of finding a better explainable model, we leave out the year and the gerne.

```{r}
### TEMP
data = subset(data_raw, select = -c(upper_genre))
### TEMP
```


```{r}
model_add_noyear = lm(popularity ~ . -year, data = data)
model_add_noyear_nogenre = lm(popularity ~ . -genre -year, data = data)
model_add_nogenre = lm(popularity ~ . -genre, data = data)
```

Let's plot the model's summary

```{r}
summary(model_add_noyear)
```

```{r}
summary(model_add_noyear_nogenre)
```

```{r}
summary(model_add_nogenre)
```


Let's do some first tests.

```{r}
check_model(model_add_noyear, data_tst)
```


```{r}
check_model(model_add_noyear_nogenre, data_tst)
```


```{r}
check_model(model_add_nogenre, data_tst)
```


### 3. Using upper genre

Fit the same models but using upper_gerne instead.


```{r}
data = subset(data_raw, select = -c(genre))
```


```{r}
model_upper_genre_add_full = lm(popularity ~ ., data = data)
model_upper_genre_add_noyear = lm(popularity ~ . -year, data = data)
model_upper_genre_add_noyear_nogenre = lm(popularity ~ . -upper_genre -year, data = data)
model_upper_genre_add_nogenre = lm(popularity ~ . -upper_genre, data = data)
```

Test these models

```{r}
check_model(model_upper_genre_add_full, data_tst)
```

```{r}
check_model(model_upper_genre_add_noyear, data_tst)
```

```{r}
check_model(model_upper_genre_add_noyear_nogenre, data_tst)
```

```{r}
check_model(model_upper_genre_add_nogenre, data_tst)
```

### 3. Transformed data

```{r}
### TEMP
data = data_trans_raw
### TEMP
```

```{r}
model_trans_add_full                        = lm(popularity ~ ., data = data)

model_trans_genre_add                 = lm(popularity ~ . -upper_genre, data = data)
model_trans_genre_add_noyear          = lm(popularity ~ . -upper_genre -year, data = data)
model_trans_genre_add_nogenre         = lm(popularity ~ . -upper_genre -genre, data = data)
model_trans_genre_add_noyear_nogenre  = lm(popularity ~ . -upper_genre -year -genre, data = data)

model_trans_upper_genre_add                 = lm(popularity ~ . -genre, data = data)
model_trans_upper_genre_add_noyear          = lm(popularity ~ . -genre -year, data = data)
model_trans_upper_genre_add_nogenre         = lm(popularity ~ . -genre -upper_genre, data = data)
model_trans_upper_genre_add_noyear_nogenre  = lm(popularity ~ . -genre -year -upper_genre, data = data)
```

```{r}
print_checks = function(model) {
  print(summary(model))
  print(check_model(model))
  
  plot(fitted(model), resid(model), col = "grey", pch = 20,
       xlab = "Fitted", ylab = "Residual",
       main = "Full Additive Model - Fitted vs Residuals")
  abline(h = 0, col = "darkorange", lwd = 2)
  
  qqnorm(resid(model), col = "darkgrey")
  qqline(resid(model), col = "dodgerblue", lwd = 2)
}
```


```{r}
print_checks(model_trans_add_full)
print_checks(model_trans_genre_add)
print_checks(model_trans_upper_genre_add)
```

