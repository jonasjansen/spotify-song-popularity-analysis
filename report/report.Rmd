---
title: "Predicting Song Popularity"
subtitle: "STAT 420, Summer 2023, UIUC - Final Data Project"
author: "Soumya Nanda, Jonas Jansen, Noam Isachar"
output:
  pdf_document: default
  theme: readable
  toc: yes
  html_document:
urlcolor: cyan
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")
```

------------------------------------------------------------------------

# Introduction

In this analysis project we decided to work on the [Spotify_1Million_Tracks](https://www.kaggle.com/datasets/amitanshjoshi/spotify-1million-tracks) which has popularity and other songs features and measures gathered by Spotify about over 1 Million tracks. Our main goal is to discover what makes a song popular and what impact different characteristics of a songs have on the song's popularity. The model we will build will also be able to predict a song's popularity.

The dataset is published and available on Kaggle and the data was extracted from the Spotify API using the Python library Spotipy. It contains information about over a Million songs from over 60,000 artists and across 82 genres between 2000 and 2023. The dataset also contains some interesting categorical variables which are some facts about each song such as the key (A, C, G#...), the mode (Major or Minor) and the time signature. In addition to those, there are numerical features about each songs which are computed by Spotify algorithms. To name a few, we have the danceability of the song, the energy, the acousticness and the valence, all in the range of 0.0 to 1.0.

Having all this musically detailed and in-depth information about so many songs provides the opportunity to use a linear model for researching what features of a song contribute to it's chance of being popular, how a song should ideally be for it to be popular, and verify the possibility of predicting how popular a song is. Knowing all the above can drive certain decisions and directions when writing a song with the goal of achieving popularity.

# Methods

We start by importing the required libraries.

```{r, warning = FALSE}
library(knitr)
library(ggplot2)
library(GGally)
library(MASS)
library(gridExtra)
library(preprocessCore)
library(lmtest)
```

Let's have the first glance of the data.

```{r}
data <- read.csv("../data/spotify_data.csv")
str(data)
```

## Data Preprocessing

We can get rid of the first column which is the index and also of the "track_id" column which is useless to us. For clarity, let's change the values of "mode" from 0 and 1 to "minor" and "major" and replace the duration from milliseconds to minutes. Finally, we can create factor variables out of some of the columns.

```{r}
data$mode <- ifelse(data$mode == 1, "major", "minor")
data$duration_m <- data$duration_ms / 1000 / 60

data$year <- factor(data$year)
data$genre <- factor(data$genre)
data$key <- factor(data$key)
data$mode <- factor(data$mode)
data$time_signature <- factor(data$time_signature)

data <- subset(data, select = -c(X, track_id, duration_ms))

str(data)
```

Looks good. The dataset now 18 variables, two of which are the artist name and track name which we won't use in the model but only for exploration and interpretation. That leaves us with the "popularity" variable which we are going to use as the response and 15 other variables that can help us as predictors. 10 of which are numeric and 5 are categorical factor variables.

Now let's check for null values.

```{r}
colSums(is.na(data))
```

There are none.

## Data Exploration and Analysis

### Data Description

We can now look at the summary of the data which shows statistics of the different variables.

```{r}
summary(data)
```

Let's explain the variables we have here. Our goal is to explain and predict the "popularity" variable, which is calculated by an algorithm of Spotify, and according to them it "is based, in the most part, on the total number of plays the track has had and how recent those plays are".

Besides the artist and track name and the year and genre which are obvious, we have some more factual categorical variables:

1.  Key: ranges from 0 to 11 and indicates the key the track is in starting from 0 = C.
2.  Mode: refers to whether the track is in major or minor scale.
3.  Time signature: An estimated time signature which specifies how many beats are in a bar.

The numerical variables mostly contain audio features of the track:

1.  Danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.
2.  Energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy.
3.  Loudness: The overall loudness of a track in decibels (dB).
4.  Speechiness: Speechiness detects the presence of spoken words in a track.
5.  Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.
6.  Instrumentalness: Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context.
7.  Liveness: Detects the presence of an audience in the recording.
8.  Valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
9.  Tempo: The overall estimated tempo of a track in beats per minute (BPM).
10. Duration: The duration of the track in minutes.

More on the variables can be read on the [Spotify API documentation](https://developer.spotify.com/documentation/web-api).

The data looks clean but there is one case of outliers in the duration of tracks. Let's keep track with maximum length of 40 minutes, which is by itself very unusual but we can still think of some songs of that length (The Orb - The Blue Room). In fact, any track longer than 40 minutes has to be considered as an album by the British Phonographic Industry. In addition, it is safe to say that the maximum duration of 100 minutes is not something we want to base our model on as it doesn't realistically reflect real songs.

```{r}
data <- data[data$duration_m <= 40, ]
summary(data$duration_m)
```

One other thing we want to verify is the 0 values n tempo.

```{r}
head(data[data$tempo == 0, 1:2], 10)
```

After listening to some of those we can verify that the 0 for tempo are legit values and these songs don't follow a beat.

Another suspicious 0 is for the popularity. Knowing Spotify, there is a lot of junk there that can't really be tagged as songs and it is possible that it ended up in this dataset and it is contaminating the data. Another possibility is that it is a bug in the dataset, since getting zero popularity and not even a fraction above it means that no streams were made. Let's see some of the tracks with zero popularity and manually verify what happened.

```{r}
head(data[data$popularity == 0, 1:2], 10)
```

After carefully checking examples, we noticed some of them have Millions of streams, like Greetings by Joni Haastrup. This makes us think that there is a problem and some songs are added with zero popularity by mistake. Let's see how many songs have zero popularity, and how many have any other number.

```{r}
print(paste("Number of tracks with zero popularity:", nrow(data[data$popularity == 0, ])))
print(paste("Number of tracks with non-zero popularity:", nrow(data[data$popularity > 0, ])))
```

For some reason tracks with zero popularity are over 10% of the dataset, which other than being suspicious is also VERY unbalanced. We decide to remove these observations as there seems to be so many of them, also in cases that it doesn't make sense.

```{r}
data <- data[data$popularity > 0, ]
summary(data)
```

### Numerical Variables Analysis

Let's start exploring the numerical variables and the relationships between them.

```{r}
num_vars <- sapply(data, is.numeric)
num_data <- data[, num_vars]
num_data_sample <- num_data[sample(nrow(num_data), 10000), ]

pair_plot_sample = ggpairs(num_data_sample, upper = list(continuous = wrap("cor", size = 6))) +
  theme_bw() + 
  theme(axis.line=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        text = element_text(size = 30))
```

```{r, warning = FALSE, fig.width=25, fig.height=15}
print(pair_plot_sample, progress = F)
```

We sampled 10,000 observations from the dataset for this pair-plot since doing it on the entire dataset would take much more time and also flood the plots with so much dots that they would become all black. A sample of 10,000 is more than enough to show the relationship between variables.

Let's highlight some interesting points:

-   The first thing to observe is how difficult it is to write a popular song. Even after we removed songs with 0 popularity the distribution is still very left-skewed and the mean is only 21.3 out of 100.

-   Looking at the main diagonal where the distribution of each variable is plotted, we can see that many of them including the popularity are skewed which hints that transformations will be needed if we want better prediction results. We will consider log, square-root, inverse and box-cox transformations for this task.

-   In terms of correlation with the response we don't have significant results which makes it more challenging to select predictors.

-   Energy has a strong positive correlation with loudness and a strong negative correlation with acousticness. This suggests that we might want to be careful using all of them in order to avoid collinearity issues. Also danceability and valence have some correlation we should take note of.

-   In general, we might want to avoid using the loudness and tempo variables in our model since some of the algorithm-generated variables are probably based on them in some way.

-   Some other observations jump out which are not related to the model we intend to build. Regarding the instrumentalness, it has some positive correlation with the duration and negative correlation with the loudness and valence, which makes sense. Many of the instrumental songs we know are indeed longer than usual and also have some quiet gloomy parts. The tempo has a positive correlation with the loudness and negative correlation with the acousticness. In reality faster and upbeat songs are usually louder than slower ones, and acoustic songs we know do tend to be slower in BPM. One more relationship that is logical is the positive one between liveness and speechiness. Concerts and live version have some spoken words in them when the artists communicate with the crowd.

After getting the hint that transformations are required, let's run the Box-Cox method on every non-negative numerical variable to see which is the recommended transformation.

```{r}
eps = 1e-8
# Function to calculate the optimal lambda for a variable using Box-Cox
get_optimal_lambda <- function(variable) {
  lm_formula <- as.formula(paste(variable, "+ eps ~ 1"))
  result <- boxcox(lm_formula, data = data, plot=FALSE)
  return(result$x[which.max(result$y)])  # Return the optimal lambda
}

# Create an empty data frame to store the results
table_optimal_lambdas <- data.frame(variable = character(), optimal_lambda = numeric(), stringsAsFactors = FALSE)

# Use a loop to get the optimal lambda for each variable
for (var in names(num_vars[num_vars])) {
  if (min(data[[var]]) < 0) {
    optimal_lambda = 1
  }
  else {
    optimal_lambda = get_optimal_lambda(var)
  }
  table_optimal_lambdas <- rbind(table_optimal_lambdas, data.frame(variable = var, optimal_lambda = optimal_lambda))
}

# Print the table
print(table_optimal_lambdas)
```

Save the transformed variables with the recommended lambdas into a new dataframe. Then, we plot the pair-plot again and see of the distributions resemble a normal distribution.

```{r}
apply_boxcox_transformation <- function(variable, lambda) {
  transformed_variable <- if (abs(lambda) < 0.01) {
    log(data[[variable]] + eps)
  } else {
    (data[[variable]]^lambda - 1) / lambda
  }
  return(transformed_variable)
}

categorical_vars <- names(data)[sapply(data, function(x) is.factor(x) || is.character(x))]

# Create a new data frame to store the transformed data
boxcox_data <- data.frame(
  sapply(names(num_vars[num_vars]), function(var) apply_boxcox_transformation(var, table_optimal_lambdas[table_optimal_lambdas$variable == var, "optimal_lambda"])),
  data[categorical_vars],  # Add the categorical columns from the original data
  stringsAsFactors = FALSE
)
boxcox_data <- boxcox_data[names(data)]
```
```{r}
boxcox_num_data <- boxcox_data[, num_vars]
boxcox_num_data_sample <- boxcox_num_data[sample(nrow(boxcox_num_data), 10000), ]

boxcox_pair_plot_sample = ggpairs(boxcox_num_data_sample, upper = list(continuous = wrap("cor", size = 6))) +
  theme_bw() + 
  theme(axis.line=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        text = element_text(size = 30))
```
```{r, warning = FALSE, fig.width=25, fig.height=15}
print(boxcox_pair_plot_sample, progress = F)
```

The distributions still look off. When Box-Cox transformations are unsatisfactory, quantile normalization emerges as a robust alternative. Unlike Box-Cox, quantile normalization is distribution-free and aligns empirical distributions across variables, ensuring fair comparisons and improved statistical analyses, even with non-normally distributed data. It provides a versatile, data-driven approach to normalize variables, making it an effective choice when dealing with datasets lacking a specific theoretical distribution.

Quantile normalization equalizes the empirical distributions of numerical data across variables by mapping each value to its corresponding quantile in a reference distribution (e.g., uniform or Gaussian). This process ensures that all variables share the same distributional properties, making the data suitable for statistical analyses and comparisons without relying on any specific theoretical distribution.

Let's perform quantile normalization on the numerical variables and the show the pair-plot again.

```{r}
quantile_data = as.data.frame(normalize.quantiles(as.matrix(num_data)))
colnames(quantile_data) = colnames(num_data)
quantile_data = cbind(quantile_data, data[categorical_vars])
quantile_data <- quantile_data[names(data)]
```

```{r}
quantile_num_data <- quantile_data[, num_vars]
quantile_num_data_sample <- quantile_num_data[sample(nrow(quantile_num_data), 10000), ]

quantile_pair_plot_sample = ggpairs(quantile_num_data_sample, upper = list(continuous = wrap("cor", size = 6))) +
  theme_bw() + 
  theme(axis.line=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        text = element_text(size = 30))
```
```{r, warning = FALSE, fig.width=25, fig.height=15}
print(quantile_pair_plot_sample, progress = F)
```

Beautiful. The distributions of the variables are not skewed and the scatterplots resemble what we are used to see when working with normally distributed data. When building the models we will most likely use the quantile normalized data.

One more interesting analysis to try is to bin the popularity into 10 chunks and see the difference in each variable across the different bins of popularity.

```{r, fig.width=20, fig.height=15}
data$popularity_bins <- cut(data$popularity, breaks = 10)
plot_list <- list()

for (column in names(data)) {
  if (column != "popularity_bins" && column != "popularity" && num_vars[column]) {
    plot <- ggplot(data, aes(x = popularity_bins, y = .data[[column]], fill = popularity_bins)) +
      geom_boxplot() +
      labs(x = "Popularity Bins", y = column, title = paste("Distribution of", column, "by Popularity Bins")) +
      theme(axis.text.x = element_blank(), legend.position = "none") +
      facet_grid(~ popularity_bins, scales = "free_x", space = "free_x", switch = "x")
    
    plot_list[[column]] <- plot
  }
}

grid.arrange(grobs = plot_list, ncol = 2)
data <- subset(data, select = -c(popularity_bins))
```

From the plots above we can see that across all the numerical predictors we have less variance and outliers as the popularity grows. They all stabilize around some range in the higher bins.

We can see a weak positive trend in the danceability, which resembles the one of the valence. This means that the popular songs tend to be happier and more danceable.

Also the energy and loudness share a similar behavior between them, but the loudness has much less variance. Anyway both of them don't seem to have an observable relationship with the popularity.

Another trend to note is that the instrumentalness and speechiness massively decrease and are almost at 0 when the popularity grows. This reveals another tip for making a popular song: don't make it instrumental are include spoken speech in it.

Maybe the clearest trend above is the negative one between the acousticness and the popularity. There are some popular acoustic songs but it sure doesn't raise your chances.

As for the tempo, its mean is pretty stable across all the bins, but the chance for outliers on both sides are decreasing as the popularity increases. Maybe a polynomial transformation will work here?

Finally, the chance of a long song to be popular is very low as most of the longer songs are in the lower half of the popularity bins.

### Categorical Variables Analysis

Now let's take a look at the impact of the categorical predictors. We start with the genre, and since it has many values and plotting would be difficult, what we can do is check the genres with the best and worst mean popularity.

```{r}
mean_popularity_by_genre <- aggregate(popularity ~ genre, data, mean)

best_mean_popularity_by_genre <- mean_popularity_by_genre[order(-mean_popularity_by_genre$popularity), ]
worst_mean_popularity_by_genre <- mean_popularity_by_genre[order(mean_popularity_by_genre$popularity), ]
```

```{r}
print(head(best_mean_popularity_by_genre, 10))
```

```{r}
print(head(worst_mean_popularity_by_genre, 10))
```

As expected, the genre greatly impacts the popularity. There is a huge difference in the mean popularity across genres.

The only issue with the genre is that there are two many of them, with 82 values. That could be a problem if we decide to interact it with some other variables, which could happen since different genres might have different recipes for success. What we can do is create another variable called "upper_genre" which will be a mapping of the current genres to a higher level genre. We will create the mapping ourselves by carefully listening, researching and examining the current genres and categorizing them into upper genres. We will use the upper genre with caution.

```{r, warning=FALSE}
genre_mapping <- list(
  "rock" = c("alt-rock", "garage", "hard-rock", "psych-rock", "rock", "rock-n-roll"),
  "metal" = c("black-metal", "death-metal", "emo", "goth", "grindcore", "hardcore", "metal", "metalcore", "heavy-metal"),
  "electronic" = c("ambient", "breakbeat", "chicago-house", "dance", "dancehall", "deep-house", "detroit-techno",
                   "drum-and-bass", "dub", "dubstep", "edm", "electro", "electronic", "hardstyle", "house",
                   "minimal-techno", "progressive-house", "techno", "trance", "party", "chill", "club", "industrial"),
  "pop" = c("cantopop", "indie-pop", "k-pop", "pop", "power-pop", "pop-film"),
  "country" = "country",
  "folk" = "folk",
  "classical/opera" = c("classical", "opera"),
  "hip-hop" = "hip-hop",
  "blues" = "blues",
  "jazz" = "jazz",
  "soul" = "soul",
  "world" = c("indian", "spanish", "swedish", "tango", "forro", "sertanejo", "salsa", "samba", "french", "german", "afrobeat"),
  "ska" = "ska",
  "punk" = c("punk", "punk-rock"),
  "funk/disco" = c("funk", "disco"),
  "trip-hop" = "trip-hop",
  "acoustic" = c("acoustic", "singer-songwriter", "songwriter", "sad", "guitar", "piano"),
  "new-age" = "new-age",
  "other" = c("comedy", "gospel", "romance", "show-tunes", "sleep", "groove")
)

map_genre <- function(genre) {
  for (key in names(genre_mapping)) {
    if (genre %in% unlist(genre_mapping[[key]])) {
      return(key)
    }
  }
}

data$upper_genre <- sapply(data$genre, map_genre)
quantile_data$upper_genre = data$upper_genre
```

While handling and categorizing the genres we noticed some inconsistencies with the genre values across different songs. Some completely not related songs were wrongly categorized to the same genre, which makes sense since the genre is an algorithm-based variable. This leads us to think that we want to try a model without considering the genre, not even in the reduced form.
Before proceeding let's see the average popularity of the new upper genres.

```{r}
mean_popularity_by_upper_genre <- aggregate(popularity ~ upper_genre, data, mean)

best_mean_popularity_by_upper_genre <- mean_popularity_by_upper_genre[order(-mean_popularity_by_upper_genre$popularity), ]
worst_mean_popularity_by_upper_genre <- mean_popularity_by_upper_genre[order(mean_popularity_by_upper_genre$popularity), ]
```

```{r}
print(head(best_mean_popularity_by_upper_genre, 10))
```

```{r}
print(head(worst_mean_popularity_by_upper_genre, 10))
```

Now we can look at the year variable.

```{r, fig.width=25, fig.height=6}
mean_popularity_by_year <- aggregate(data$popularity, by = list(year = data$year), mean)
mean_popularity_by_year <- reshape2::melt(mean_popularity_by_year, id.vars = "year")

ggplot(mean_popularity_by_year, aes(x = year, y = value, group = variable, color = variable)) +
  geom_line() +
  geom_point() +
  labs(x = "Year", y = "Mean Popularity", title = "Mean Popularity by Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 22)) +
  theme(legend.position = "none")
```

Since the popularity is based also on whether the track was recently played, we see greater popularity to recent songs which makes sense. However, our main goal is to understand what elements of a song have impact on making it popular, and when writing a song it is not possible to change the year it is released in. In other words, the year is not going to help us say what makes a song popular since the popularity is biased towards recent songs and the time is not something an artist controls.

In order to be able to explain the model but also utilize the year in our predictions, we will use the year variable to interact with all the other variables, and then we can select each year and see how the parameters of the other variables change. For example, by interacting the year with the rest we will be able to select the year 2023 and see how a song should be in order to maximize its chances of popularity in 2023.

Despite all that, we are still curious to see the variation in the characteristics of songs across different years, and see what features of songs from different years contribute to its popularity right now. Let's see the mean of each variable as a function of the year, and also a plot of correlation with the popularity by year.

```{r, fig.width=25, fig.height=8}
mean_data <- aggregate(data[, num_vars], by = list(year = data$year), mean)
mean_data = subset(mean_data, select = -c(popularity, tempo, duration_m, loudness))
mean_melted <- reshape2::melt(mean_data, id.vars = "year")

ggplot(mean_melted, aes(x = year, y = value, group = variable, color = variable)) +
  geom_line() +
  geom_point() +
  labs(x = "Year", y = "Mean Value",
       title = "Mean of [0, 1] Ranged Numerical Variables as a Function of Year") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 22))
```

```{r, fig.width=25, fig.height=8}
cor_data <- data.frame(year = unique(data$year))
cor_data$year <- as.numeric(as.character(cor_data$year))

for (var in names(num_vars[num_vars])) {
  if (var != "popularity"){
    cor_values <- sapply(unique(data$year), function(y) {
      subset_data <- subset(data, as.numeric(as.character(year)) == y)
      cor(subset_data[[var]], subset_data$popularity)
    })
    
    cor_data[var] <- cor_values
  }
}

cor_melted <- reshape2::melt(cor_data, id.vars = "year")

ggplot(cor_melted, aes(x = year, y = value, group = variable, color = variable)) +
  geom_line() +
  geom_point() +
  labs(x = "Year", y = "Correlation with Popularity",
       title = "Correlation with Popularity Over the Years") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(size = 22))
```

To our surprise, there are no significant trends in the means over the years. The only visible changes are the drop in the valence which generally means that songs became sadder, and the rise and fall of energy that reached a peak around 2010.

In the correlations plot we see a clear rise in the impact danceability and energy have on the popularity, especially after 2020. Groovy energetic songs are becoming more and more likable. The duration went from 0.0 to almost -0.2 at some point, which highlights that popular songs are getting shorter.

Now let's see how the time signature, key and mode affect the popularity.

```{r, fig.height=10}
ts_pop = ggplot(data, aes(x = time_signature, y = popularity, fill=time_signature)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  labs(x = "Time Signature", y = "Popularity", title = "Distribution of Popularity by Time Signature")

key_pop = ggplot(data, aes(x = key, y = popularity, fill=key)) +
  geom_boxplot() +
  theme(legend.position = "none") + 
  labs(x = "Key", y = "Popularity", title = "Distribution of Popularity by Key")

mode_pop = ggplot(data, aes(x = mode, y = popularity, fill=mode)) +
  geom_boxplot() +
  theme(legend.position = "none") + 
  labs(x = "Mode", y = "Popularity", title = "Distribution of Popularity by Mode")

grid.arrange(ts_pop, key_pop, mode_pop, ncol = 1)
```

There are no significant changes in the distribution of the popularity between different values of time signature, key or mode. Maybe we should check the combination of key and mode since they often touch similar characteristics of a song.

```{r, fig.width=16, fig.height=5}
data$key_mode_combination <- interaction(data$mode, data$key)

combined_plot <- ggplot(data, aes(x = key_mode_combination, y = popularity, fill = mode)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  labs(x = "Key and Mode", y = "Popularity", title = "Distribution of Popularity by Key and Mode") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~ key_mode_combination, scales = "free_x", ncol = 24)

print(combined_plot)

data <- subset(data, select = -c(key_mode_combination))
```

Still doesn't look significant for the popularity. In terms of the mean and even the outliers the boxplots don't look too different.

There is little chance that we will need the time signature, key or mode in the final model.

### Conclusions

Before building the model, we can lay out a few conclusions from the sections above that will help us in building a better model and more importantly, write a hit song!

-   The distribution of the popularity variable is left-skewed, indicating that most songs have relatively low popularity scores, with only a few reaching higher scores. To tackle that in our model we might want to try transforming the response, together with some other numerical variables that are skewed. After using the Box-Cox method we retrieved the optimal lambdas for each variables and implemented it in a dedicated dataframe. The result was still unsatisfactory so we had to use a more robust way of normalizing data and forcing it into a normal distribution, such as quantile normalization. The normalized data was saved into a dataframe which we are likely to use when fitting models. 

-   There is no single variable that is strongly correlated with the popularity. This means that a combination of factors is likely to influence the popularity of a song, and that we will need to try a few interactions.

-   The most popular songs are usually short, upbeat, energetic, not instrumental or acoustic and do not include spoken words.

-   There are some potential collinearity issues we should avoid. Energy, loudness and acousticness have some relationship between them (acousticness seems to impact the popularity the most out of them), and also danceability and valence correlate. We should be careful using loudness and tempo because they are most probably used to calculate other variables.

-   The genre is a problematic variable. The average popularity across different genres is variant, so it has some importance. Together with that, there a many different genres which could make the models complex. That's why we introduced the reduced upper genre. Also there are many errors with the genre since it was created by a Spotify algorithm, possibly using the other variables we have in the dataset.

-   Because of the way the popularity is computed, the year is very important as well. However, we want to be able to say how to write a song for it to be popular, and since the year of release is not something you control we would prefer to interact that variable with the numerical variables we choose to include, which will allow us to specify the recipe for popularity on each year.

-   The time signature, key and mode don't seem to affect the popularity so much.

Now we can proceed and build some models.

## Model Building

### Define Test Criteria

First we split the data sets into 

Split the data into 70% train data and 30% test data. 


```{r}
ratio = 0.7

# normal data set
data_fit <- subset(data, select = -c(artist_name, track_name))

sample_size = floor(ratio * nrow(data_fit))
data_idx = sample(nrow(data_fit), sample_size)
data_trn = data_fit[data_idx, ]
data_tst = data_fit[-data_idx, ]


# quantile normalized data set
quantile_data_fit <- subset(quantile_data, select = -c(artist_name, track_name))

sample_size = floor(ratio * nrow(quantile_data_fit))
quantile_data_idx = sample(nrow(quantile_data_fit), sample_size)
quantile_data_trn = quantile_data_fit[quantile_data_idx,]
quantile_data_tst = quantile_data_fit[-quantile_data_idx, ]
```


Define a function which is performing several tests on a given model and test data.
Note that the shapiro test is limited to 5000 residuals. Since all data sets used here are way larger and therefore the number of residuals too,
a random sample size of 5000 residuals is selected.
This makes the result of that test somewhat unreliable, but it still give us an idea how good or bad the model might be.

```{r}
check_model = function(model, test_data){
  # 
  sample_idx = sample(length(resid(model)), 5000)
  residuals_sample = resid(model)[sample_idx]
  
  # shapiro
  shapiro =  shapiro.test(residuals_sample)$p.value
  
  # bp test
  bptest = bptest(model)$p.value
  
  # leverage
  high_leverage_count = sum(hatvalues(model) > 2 * mean(hatvalues(model)))
  
  # outliers
  outliers_count = length(rstandard(model)[abs(rstandard(model)) > 2])
  
  # influence
  influence_count = sum(cooks.distance(model) > 4 / length(cooks.distance(model)))
  
  # vif
  vif_values <- car::vif(model)
  predictor_names = names(model$coefficients)[-1]
  high_vif_count = sum(vif_values > 5)
  high_vif_predictors = predictor_names[vif_values > 5]

  
  # loocv_rmse
  loocv_rmse = sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
  
  # adjusted r squared
  adjusted_r_squared = summary(model)$adj.r.squared

  # Get rsme using the test data
  predictions <- predict(model, newdata = test_data)
  rsme <- sqrt(mean((test_data$popularity - predictions)^2))

  # Creating a data frame to store the results
  results = data.frame(
    shapiro = shapiro,
    bptest = bptest,
    high_leverage_count = high_leverage_count,
    outliers_count = outliers_count,
    influence_count = influence_count,
    high_vif_count = high_vif_count,
    high_vif_predictors = paste(high_vif_predictors, collapse = ", "),
    rsme = rsme,
    loocv_rmse = loocv_rmse,
    adjusted_r_squared = adjusted_r_squared
  )

  results
}
```

Define a function to plot both the Fitted vs Residuals plot and the Q-Q Plot

```{r}
# TODO: Pass main and labels to function.
plot_model <- function(model) {
  # Fitted vs Residuals Plot
  plot(fitted(model), resid(model), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Data from Model 3")
  abline(h = 0, col = "darkorange", lwd = 2)
  
  # Q-Q Plot
  qqnorm(resid(model), main = "Normal Q-Q Plot", col = "darkgrey")
  qqline(resid(model), col = "dodgerblue", lwd = 2)
}

```

### Full Additive Model

The first model we build is a full additive one including all predictors. One exception is on the upper genre, since this sould be a replacement for gerne in a better explainable and useful model.
The use data is the untransformed one. 

```{r}
model_add_full = lm(popularity ~ . -upper_genre, data = data_trn)
```

Let's see how good the model performs

```{r}
summary(model_add_full)
```

```{r}
check_model(model_add_full, data_tst)
```


```{r}
plot_model(model_add_full)
```


TODO: Describe the model


### Interaction ???


# TODO: Fit a model with all two-way interactions.



### Data Transformation

The next step is to focus on the very suspect normality and constant variance assumptions of the full additive model. 

```{r}
model_add_quant_full = lm(popularity ~ . -upper_genre, data = quantile_data_trn)
```

```{r}
summary(model_add_quant_full)
```

```{r}
check_model(model_add_quant_full, quantile_data_tst)
```

```{r}
plot_model(model_add_quant_full)
```


### Collinearity

# TODO: Colinearity
# TODO: outliers

### More Explainability


```{r}
model_explain = lm(popularity ~ . -genre -year, data = quantile_data_trn)
```

```{r}
summary(model_explain)
```

```{r}
check_model(model_explain, quantile_data_tst)
```

```{r}
plot_model(model_explain)
```

TODO: Tell about model.


# Results

# Discussion

# Appendix

The report was composed and written by Soumya Nanda, Jonas Jansen and Noam Isachar.




